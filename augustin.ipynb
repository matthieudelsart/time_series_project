{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/train_preprocessed.csv')\n",
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(index=35065, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `data` is your DataFrame and `id` is the timestamp column\n",
    "data_train['id'] = pd.to_datetime(data_train['id'])\n",
    "data_train = data_train.copy()\n",
    "data_train['time_idx'] = (data_train['id'] - data_train['id'].min()) / pd.Timedelta(hours=1)\n",
    "data_train['time_idx'] = data_train['time_idx'].astype(int)\n",
    "data_train['location']=\"Montsouris\"\n",
    "data_train['car_flow'] = data_train['car_flow'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['holiday_type'] = np.where(data_train['is_holiday'] == 1, 'holiday', \n",
    "                              np.where(data_train['is_jour_ferie'] == 1, 'ferie', np.nan))\n",
    "data_train = data_train.drop(columns=['is_holiday','is_jour_ferie'])\n",
    "data_train['holiday_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 502\n",
    "max_encoder_length = 365*24*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cutoff = data_train[\"time_idx\"].max() - max_prediction_length\n",
    "training_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Year'] = data_train['Year'].astype(str)\n",
    "data_train['Month'] = data_train['Month'].astype(str)\n",
    "data_train['Day'] = data_train['Day'].astype(str)\n",
    "data_train['is_weekend'] = data_train['is_weekend'].astype(str)\n",
    "data_train['DayOfYear'] = data_train['DayOfYear'].astype(str)\n",
    "data_train['HourOfDay'] = data_train['HourOfDay'].astype(str)\n",
    "data_train['Weekday'] = data_train['Weekday'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TimeSeriesDataSet(\n",
    "    data_train[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=['valeur_NO2', 'valeur_CO', 'valeur_O3', 'valeur_PM10','valeur_PM25'],\n",
    "    group_ids=[\"location\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_known_categoricals=['Year','Month', 'Day', 'is_weekend','DayOfYear', 'HourOfDay', 'Weekday','holiday_type'],\n",
    "    variable_groups={\"special_days\": [\"holiday_type\"]},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"time_idx\", 'DayOfYear_sin', 'DayOfYear_cos', 'HourOfDay_sin', 'HourOfDay_cos','Weekday_sin', 'Weekday_cos','precipitation', 'wind_speed', 'temperature', 'humidity','pressure', 'visibility', 'global_solar_radiation'],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        'valeur_NO2',\n",
    "        'valeur_CO',\n",
    "        'valeur_O3',\n",
    "        'valeur_PM10',\n",
    "        'valeur_PM25',\n",
    "        'car_flow'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following is not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    dataset,  # the dataset we defined previously\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # model capacity\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=[1,1,1,1,1],  # Number of target variables\n",
    "    loss=QuantileLoss()  # Use QuantileLoss for multi-output forecasting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=\"auto\" if torch.cuda.is_available() else 1  # Set to 1 for CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(tft, train_dataloaders=train_dataloader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainer = Trainer(max_epochs=30, gpus=1 if torch.cuda.is_available() else 0)  # Use 1 GPU if available"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"id\"] = pd.to_datetime(data_train[\"id\"])\n",
    "features = ['id', 'is_holiday', 'is_jour_ferie', 'precipitation',\n",
    "       'wind_speed', 'temperature', 'humidity', 'pressure', 'visibility',\n",
    "       'global_solar_radiation', 'Year', 'is_weekend', 'DayOfYear',\n",
    "       'HourOfDay', 'DayOfYear_sin', 'DayOfYear_cos', 'HourOfDay_sin',\n",
    "       'HourOfDay_cos', 'Weekday_sin', 'Weekday_cos']\n",
    "data_train[\"location\"] = \"Montsouris\"\n",
    "data_train['time_idx'] = ((data_train['id'] - data_train['id'].min()).dt.total_seconds() // 3600).astype(\"int\")\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_length = 7 * 24\n",
    "max_prediction_length = 502  # Forecast 502 hours into the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(index=35065, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "split_idx = int(data_train[\"time_idx\"].max() * 0.8)  # 80% for training, adjust as needed\n",
    "\n",
    "train_data = data_train[data_train[\"time_idx\"] <= split_idx]\n",
    "val_data = data_train[data_train[\"time_idx\"] > split_idx]\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    train_data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=[\"valeur_NO2\", \"valeur_CO\", \"valeur_O3\", \"valeur_PM10\", \"valeur_PM25\"],\n",
    "    group_ids=[\"location\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_unknown_reals=[\"valeur_NO2\", \"valeur_CO\", \"valeur_O3\", \"valeur_PM10\", \"valeur_PM25\"],\n",
    "    time_varying_known_reals=features,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "val_dataset = TimeSeriesDataSet(\n",
    "    val_data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=[\"valeur_NO2\", \"valeur_CO\", \"valeur_O3\", \"valeur_PM10\", \"valeur_PM25\"],\n",
    "    group_ids=[\"location\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    time_varying_unknown_reals=[\"valeur_NO2\", \"valeur_CO\", \"valeur_O3\", \"valeur_PM10\", \"valeur_PM25\"],\n",
    "    time_varying_known_reals=features,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLoss:\n",
    "    def __init__(self, losses):\n",
    "        self.losses = losses\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        total_loss = 0\n",
    "        for i, loss_fn in enumerate(self.losses):\n",
    "            total_loss += loss_fn(y_pred[..., i], y_true[..., i])\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models.temporal_fusion_transformer import TemporalFusionTransformer\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# Define TFT model\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=0.03,  # You may adjust this\n",
    "    hidden_size=16,  # Size of the network layers\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=[1, 1, 1, 1, 1], \n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters in model: {tft.size()/1e3:.1f}k\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models.temporal_fusion_transformer import TemporalFusionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "isinstance(tft, pl.LightningModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=5)],\n",
    "    precision=16 if torch.cuda.is_available() else 32,\n",
    "    log_every_n_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataset.to_dataloader(train=True, batch_size=64, num_workers=4),\n",
    "    val_dataloaders=val_dataset.to_dataloader(train=False, batch_size=64, num_workers=4),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "class TFTLightningWrapper(pl.LightningModule):\n",
    "    def __init__(self, tft_model):\n",
    "        super().__init__()\n",
    "        self.model = tft_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.model.loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.model.loss(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models.temporal_fusion_transformer import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# Instantiate the TemporalFusionTransformer model\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=[1, 1, 1, 1, 1],  # Adjusted for each target variable\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# Wrap the model in the custom LightningModule wrapper\n",
    "tft_wrapped = TFTLightningWrapper(tft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=30\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    tft_wrapped,\n",
    "    train_dataloaders=train_dataset.to_dataloader(train=True, batch_size=64, num_workers=4),\n",
    "    val_dataloaders=val_dataset.to_dataloader(train=False, batch_size=64, num_workers=4),\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
